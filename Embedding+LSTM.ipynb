{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets classification using words embedding and LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yassine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yassine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, concatenate, Dropout, concatenate,Input\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Label</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304271250237304833</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'#SecKerry: The value of the @StateDept and @U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304834304222064640</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'@rraina1481 I fear so'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303568995880144898</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'Watch video highlights of the #wwc13 final be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304366580664528896</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'RT @chelscanlan: At Nitro Circus at #AlbertPa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296770931098009601</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'@cricketfox Always a good thing. Thanks for t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetId     Label  \\\n",
       "0  304271250237304833  Politics   \n",
       "1  304834304222064640  Politics   \n",
       "2  303568995880144898    Sports   \n",
       "3  304366580664528896    Sports   \n",
       "4  296770931098009601    Sports   \n",
       "\n",
       "                                           TweetText  \n",
       "0  '#SecKerry: The value of the @StateDept and @U...  \n",
       "1                            '@rraina1481 I fear so'  \n",
       "2  'Watch video highlights of the #wwc13 final be...  \n",
       "3  'RT @chelscanlan: At Nitro Circus at #AlbertPa...  \n",
       "4  '@cricketfox Always a good thing. Thanks for t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data \n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing tweets, preparing embedding matrices, creating and training LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    \"\"\"\n",
    "    A whole machine learning pipeline for tweets classification using word embeddings and LSTM\n",
    "    \"\"\"\n",
    "    # init method\n",
    "    def __init__(self, X: list, Y: list, embed_path: str, embed_dim: int, epochs=10, batch_size=256):\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.embed_path = embed_path\n",
    "        self.embed_dim = embed_dim\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def preprocess(self):\n",
    "        \n",
    "        # Split \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            self.X, self.Y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Preprocecing the text\n",
    "        X_train = [self.clean_text(text) for text in X_train]\n",
    "        X_test = [self.clean_text(text) for text in X_test]\n",
    "        Y_train = np.asarray(Y_train)\n",
    "        Y_test = np.asarray(Y_test)\n",
    "        \n",
    "        # Tokenizing the text\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(X_train)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # Creating the embedding matrix\n",
    "        embedding = Embeddings(self.embed_path, self.embed_dim)\n",
    "        self.embedding_matrix = embedding.create_embedding_matrix(tokenizer, len(tokenizer.word_counts))\n",
    "\n",
    "        # Creating the padded input for the deep learning model\n",
    "        self.max_len = np.max([len(text.split()) for text in X_train])\n",
    "        X_train = self.string_to_tensor(X_train, self.tokenizer, self.max_len)\n",
    "        X_test = self.string_to_tensor(X_test, self.tokenizer, self.max_len)\n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    # Train rnn model\n",
    "    def train(self):\n",
    "        \n",
    "        model = self.Rnn_model(\n",
    "            embedding_matrix=self.embedding_matrix, \n",
    "            embedding_dim=self.embed_dim, \n",
    "            max_len=self.max_len\n",
    "        )\n",
    "        model.fit(\n",
    "            self.X_train,\n",
    "            self.Y_train, \n",
    "            batch_size=self.batch_size, \n",
    "            epochs=self.epochs\n",
    "        )\n",
    "        self.model = model\n",
    "        return self.model\n",
    "    \n",
    "    # Model architecture \n",
    "    def Rnn_model(self, embedding_matrix, embedding_dim, max_len):\n",
    "        \"\"\"\n",
    "        Recurrent neural network. The embedding layer is supposed \n",
    "        to take an embedding matrix for pretrained weights\n",
    "        \"\"\"\n",
    "\n",
    "        inp1 = Input(shape=(max_len,))\n",
    "        x = Embedding(embedding_matrix.shape[0], embedding_dim, weights=[embedding_matrix])(inp1)\n",
    "        x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "        x = Bidirectional(LSTM(150))(x)\n",
    "        x = Dense(128, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)    \n",
    "        model = Model(inputs=inp1, outputs=x)\n",
    "\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "        return model\n",
    "    \n",
    "    def predict(self, text: list):\n",
    "        \n",
    "        text = [self.clean_text(t) for t in text]\n",
    "        text = self.string_to_tensor(text, self.tokenizer, self.max_len)\n",
    "        \n",
    "        yhat = [x[0] for x in self.model.predict(text).tolist()]\n",
    "        \n",
    "        return [1 if x > 0.5 else 0 for x in yhat]\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \n",
    "        # If X_test is provided we make predictions with the created model\n",
    "        if len(self.X_test)>0:\n",
    "            #X_test = [self.clean_text(text) for text in self.X_test]\n",
    "            #X_test = self.string_to_tensor(self.X_test, self.tokenizer, self.max_len)\n",
    "            yhat = [x[0] for x in self.model.predict(self.X_test).tolist()]\n",
    "            \n",
    "            self.yhat = yhat\n",
    "\n",
    "            # If true labels are provided we calculate the accuracy of the model\n",
    "            if len(self.Y_test)>0:\n",
    "                self.acc = accuracy_score(self.Y_test, [1 if x > 0.5 else 0 for x in yhat])\n",
    "                return self.acc\n",
    "                \n",
    "    # Embedding\n",
    "    def get_coefs(self, word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    def get_embedding_index(self):\n",
    "        embeddings_index = dict(self.get_coefs(*o.split(\" \")) for o in open(self.embed_path, errors='ignore'))\n",
    "        return embeddings_index\n",
    "\n",
    "    def create_embedding_matrix(self, tokenizer, max_features):\n",
    "        \"\"\"\n",
    "        A method to create the embedding matrix\n",
    "        \"\"\"\n",
    "        model_embed = self.get_embedding_index()\n",
    "\n",
    "        embedding_matrix = np.zeros((max_features + 1, self.embed_dim))\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index > max_features:\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    embedding_matrix[index] = model_embed[word]\n",
    "                except:\n",
    "                    continue\n",
    "        return embedding_matrix\n",
    "\n",
    "    def string_to_tensor(self, string_list: list, tokenizer, max_len) -> list:\n",
    "        \"\"\"\n",
    "        A method to convert a string list to a tensor for a deep learning model\n",
    "        \"\"\"    \n",
    "        string_list = tokenizer.texts_to_sequences(string_list)\n",
    "        string_list = pad_sequences(string_list, maxlen=max_len)\n",
    "\n",
    "        return string_list\n",
    "    \n",
    "    def clean_text(self, t: str) -> str:\n",
    "        \"\"\"\n",
    "        A method to clean tweets from stopword, links and punctuations.\"\n",
    "        \"\"\"\n",
    "        # Cleaning the urls\n",
    "        t = re.sub(r'https?://\\S+|www\\.\\S+', '', t)\n",
    "\n",
    "        # Cleaning the html elements\n",
    "        t = re.sub(r'<.*?>', '', t)\n",
    "\n",
    "        # Removing the punctuations\n",
    "        for x in t.lower(): \n",
    "            if x in string.punctuation: \n",
    "                t = t.replace(x, \"\") \n",
    "\n",
    "        # Converting the text to lower\n",
    "        t = t.lower()\n",
    "\n",
    "        # Removing stop words\n",
    "        t = ' '.join([word for word in t.split() if word not in stopwords.words('english')])\n",
    "\n",
    "        # Cleaning the whitespaces\n",
    "        t = re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "        return t       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {0: \"Politics\",\n",
    "              1: \"Sports\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unprocessed tweets\n",
    "X = data['TweetText'].tolist()\n",
    "\n",
    "# labels : Sports = 1 and Politics = 0\n",
    "class_dict = {0: \"Politics\",\n",
    "              1: \"Sports\"}\n",
    "\n",
    "Y = [list(class_dict.keys())[list(class_dict.values()).index(i)] for i in data['Label'].tolist()]\n",
    "\n",
    "embed_path=\"glove.6B.300d.txt\"\n",
    "embed_dim=300\n",
    "\n",
    "classifier = Classifier(X, Y, embed_path, embed_dim, epochs=6, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "classifier.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "4567/4567 [==============================] - 131s 29ms/sample - loss: 0.3459\n",
      "Epoch 2/6\n",
      "4567/4567 [==============================] - 132s 29ms/sample - loss: 0.1291\n",
      "Epoch 3/6\n",
      "4567/4567 [==============================] - 127s 28ms/sample - loss: 0.0714\n",
      "Epoch 4/6\n",
      "4567/4567 [==============================] - 144s 32ms/sample - loss: 0.0396\n",
      "Epoch 5/6\n",
      "4567/4567 [==============================] - 151s 33ms/sample - loss: 0.0245\n",
      "Epoch 6/6\n",
      "4567/4567 [==============================] - 145s 32ms/sample - loss: 0.0117\n"
     ]
    }
   ],
   "source": [
    "# Start training \n",
    "model = classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "acc = classifier.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9376915219611849"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>predicted_Lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>306486520121012224</td>\n",
       "      <td>'28. The home side threaten again through Maso...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286353402605228032</td>\n",
       "      <td>'@mrbrown @aulia Thx for asking. See http://t....</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289531046037438464</td>\n",
       "      <td>'@Sochi2014 construction along the shores of t...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306451661403062273</td>\n",
       "      <td>'#SecKerry\\u2019s remarks after meeting with F...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297941800658812928</td>\n",
       "      <td>'The #IPLauction has begun. Ricky Ponting is t...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>282023761044189184</td>\n",
       "      <td>'Qualifier 1 and Eliminator games will be play...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>303879735006601216</td>\n",
       "      <td>@reesedward Hi Edward, it's not a #peacekeepin...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>297956846046703616</td>\n",
       "      <td>'Perera was @SunRisersIPL first #IPL purchase ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>304265049537658880</td>\n",
       "      <td>'#SecKerry: Thanks to Senator @TimKaine, @RepR...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>306430391928115200</td>\n",
       "      <td>Here's a picture from our official Pinterest a...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TweetId                                          TweetText  \\\n",
       "0     306486520121012224  '28. The home side threaten again through Maso...   \n",
       "1     286353402605228032  '@mrbrown @aulia Thx for asking. See http://t....   \n",
       "2     289531046037438464  '@Sochi2014 construction along the shores of t...   \n",
       "3     306451661403062273  '#SecKerry\\u2019s remarks after meeting with F...   \n",
       "4     297941800658812928  'The #IPLauction has begun. Ricky Ponting is t...   \n",
       "...                  ...                                                ...   \n",
       "2605  282023761044189184  'Qualifier 1 and Eliminator games will be play...   \n",
       "2606  303879735006601216  @reesedward Hi Edward, it's not a #peacekeepin...   \n",
       "2607  297956846046703616  'Perera was @SunRisersIPL first #IPL purchase ...   \n",
       "2608  304265049537658880  '#SecKerry: Thanks to Senator @TimKaine, @RepR...   \n",
       "2609  306430391928115200  Here's a picture from our official Pinterest a...   \n",
       "\n",
       "     predicted_Lables  \n",
       "0              Sports  \n",
       "1              Sports  \n",
       "2            Politics  \n",
       "3            Politics  \n",
       "4              Sports  \n",
       "...               ...  \n",
       "2605           Sports  \n",
       "2606         Politics  \n",
       "2607           Sports  \n",
       "2608         Politics  \n",
       "2609         Politics  \n",
       "\n",
       "[2610 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_text = test_df[\"TweetText\"].tolist()\n",
    "pred_list = [pred for pred in classifier.predict(test_text)]\n",
    "test_df[\"predicted_Lables\"] = [class_dict[cls] for cls in pred_list]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>predicted_Lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm pretty sure that EN-Nesiry will play in a ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump lost the election.</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obama was better than trump</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iran killed another country's president</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text predicted_Lables\n",
       "0  I'm pretty sure that EN-Nesiry will play in a ...           Sports\n",
       "1                           Trump lost the election.         Politics\n",
       "2                        Obama was better than trump         Politics\n",
       "3            Iran killed another country's president         Politics"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"I'm pretty sure that EN-Nesiry will play in a better team in Europe.\", \"Trump lost the election.\", \n",
    "        \"Obama was better than trump\", \"Iran killed another country's president\",]\n",
    "\n",
    "df = pd.DataFrame(np.array(text), columns=[\"Text\"])\n",
    "pred_list = [pred for pred in classifier.predict(text)]\n",
    "df[\"predicted_Lables\"] = [class_dict[cls] for cls in pred_list]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
